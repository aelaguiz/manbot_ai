{"title": "Why Stupid People Think They're Smart [The Dunning-Kruger Effect]", "video_id": "TT81fe2IobI", "video_url": "https://www.youtube.com/watch?v=TT81fe2IobI", "description": "How knowledge works and why stupid people think they're smarter than the smart people who think they're stupid.\n\n(The Dunning-Kruger Effect)\n\nThe Challenge Your Beliefs Course (as mentioned in the video): https://mrk.mn/3MnV3Ob\n\nLike. Subscribe. Comment.\n\n-\n\nSign up for my newsletter to receive three actionable pieces of advice each week that could change your life - free sign up here: http://bit.ly/3JRg3NX\n\nIf you are not already a member of my premium membership, get access to my courses and exclusive writing here: http://bit.ly/3LwHWfi\n\nI am Mark Manson, 3x #1 NY Times bestselling author of:\n\nThe Subtle Art of Not Giving a F*ck - https://mrk.mn/3svfxcu\nEverything Is F*cked: A Book About Hope - https://mrk.mn/2RNxVAD\n\nI share other types of content to make you a less awful human in these places:\n\nhttps://instagram.com/markmanson/\nhttps://twitter.com/IAmMarkManson\nhttps://facebook.com/Markmansonnet/\nhttps://linkedin.com/in/markmanson/\nhttps://www.tiktok.com/@iammarkmanson\n\nThanks for watching.", "published_at": "2022-10-12T13:15:01Z", "channel_id": "UC0TnW9acNxqeojxXDMbohcA", "channel_title": "Mark Manson", "tags": ["mark manson", "markmanson", "dunning-kruger effect", "dunning kruger", "dunning kruger effect", "stupid people", "dumb people", "illusory superiority", "the dunning kruger effect", "why are people stupid", "what is the dunning kruger effect", "why do stupid people think they are smart", "dunning kruger effect in action", "dunning\u2013kruger effect", "smart people", "david dunning ted talk", "dunning-kruger effect in tamil", "cognitive biases", "cognitive bias explained", "the subtle art of not giving a f*ck"], "category_id": "27", "live_broadcast_content": "none", "duration": 659.0, "dimension": "2d", "definition": "hd", "caption": "true", "view_count": 3576927, "like_count": 123894, "comment_count": 11112, "channel_info": {"title": "Mark Manson", "description": "3x #1 NY Times Bestselling Author. World Champion Non-Fuck-Giver.\n", "subscriber_count": "1350000", "total_views": "54855495", "total_videos": "100"}, "comments": [], "file_path": "/Users/aelaguiz/workspace/fb_book/audio/raws/TT81fe2IobI.mp3", "transcription": "The English philosopher Bertrand Russell once said, The whole problem with the world is that fools and fanatics are so sure of themselves, while wiser people are so full of doubt. In psychology, what Russell described is more popularly known as the Dunning-Kruger effect. This effect finds that people who are bad at something tend to believe that they're actually good at it, and people who are good at something tend to believe that they are bad at it. Elderly people who believe they're better drivers than most are actually four times more likely to make unsafe driving errors. Gun owners who think they're highly knowledgeable about gun safety score the lowest on tests about gun safety. Medical lab workers who rate themselves as highly competent in their jobs are actually the worst at their jobs. The lowest performing college students dramatically overestimate their performance on exams. The lowest performers in a debate competition wildly overestimate how well they do. People with the unhealthiest lifestyle habits rate themselves as far healthier than they actually are. People who score poorly on cognitive reasoning and analytical thinking tests severely overestimate their cognitive and analytical abilities. But why does this happen? To understand, let's break knowledge down into four quadrants. So there are known knowns, things that we know that we know, like, I know I know how to ride a bike. There are known unknowns, things that we know that we don't know, for example, I have no fucking clue how quantum physics works. And then there are unknown knowns, things that you forgot you knew or you don't realize that you know. Like you still remember how to drive to the supermarket from your childhood home. You just forgot that you knew that. And then there are unknown unknowns, stuff that you don't know that you don't know. When we are an amateur at something, we are very aware of the things that we know we know, and we're completely oblivious to the things that we don't know. Let's use basketball as an example. If you know nothing about basketball, it seems simple enough. You throw a ball into the net. You know what you know and don't know what you don't know. But as you start to learn more about basketball, you discover that there are a lot of nuances. How you shoot the ball, the mechanics of your elbow, wrist, and forearm, how you position the ball in your hand, understanding the different shots, a fadeaway, a jumper, a layup, a finger roll, an alley-oop. You're beginning to become aware of all the things you don't know, and there's a lot that you don't know. Let's say you spend another year working on basketball. You've mastered a bunch of different shots and learned to shoot with good form. Now you're getting into the weeds of defensive schemes, hand checking, picks and rolls, setting various kinds of screens. At this point, you're no longer even thinking about your shooting form or how to hit a free throw. You've forgotten you know this stuff. It's unconscious. It's automatic. It's the stuff you know, but you forgot you know, and there's a ton of it. As you can see, the difference between an amateur and a professional is that an amateur's knowledge is known to them. Therefore, they get to feel smart about it. But an expert, so much of their knowledge is either unconscious and automatic, or it's knowledge of what they still need to learn. Another way to visualize this shift is to think of knowledge as a circle. The area within the circle is what you know about a topic, and the border is the horizon of your knowledge, or everything that you're aware of that you don't know yet. This border is what determines our uncertainty or doubt. Interestingly, as the size of your circle grows larger, the horizon of your knowledge also grows larger. The more you know, the more you know that you don't know. But something else happens as well as you gain knowledge. As you implement information and it becomes automatic, you forget that you know it. So there's a second border inside the first. This smaller circle is everything that you've forgotten you know. So not only is the expert's horizon of doubt much longer, most of their knowledge is also unconscious. They forgot that they know it because it strikes them as so obvious and immediate, why even think about it? The idiot thinks he knows everything because he literally doesn't have enough knowledge to know better. Meanwhile, the expert thinks he knows nothing because he is so aware of all the ways in which he may be wrong. Now I know what you're probably doing right now. It's probably the same thing I did and most people do when they learn about the Dunning-Kruger effect. You think to yourself, Good thing I know about this Dunning-Kruger effect thing because you know, I'm super aware of all my flaws. That makes me like an expert at fucking everything. So this is the tricky thing about learning about cognitive biases. We would like to think that because we're aware of all the ways our mind fucks up, that we are somehow immune to those fuck-ups. But once again, we are not. Once again, we are so wrong. Because again and again, research has shown that educating people about their cognitive biases doesn't really make them any less susceptible to cognitive biases. And that is the most frustrating thing about the Dunning-Kruger effect. It is so hard to overcome both in others but also in ourselves. Because here's the thing, they're called blind spots for a reason. You can't fucking see them. How do you fix something that you can't see in yourself? This is the paradox of trying to overcome our own ignorance. The very thing that would help us see our mistakes is exactly what would prevent us from making them in the first place. Part of the problem is that there is a comfort in the feeling of knowing. People don't like uncertainty. Settling on a belief, whether it's true or not, is a way to resolve anxiety within ourselves. So our minds often default to believing things even if we don't have a whole lot of evidence for them. And unfortunately, ripping on people for being fucking stupid doesn't really help the situation either. Anybody who's gotten in a dumbass argument in comment threads can tell you this from experience. Again and again, psychology has shown that when people's beliefs are challenged, they don't change their minds. They actually get more rigid and defensive. So what are we supposed to do? Well, starting with ourselves, I think it's an important practice to perhaps hold fewer opinions or at least hold them less strongly. This means being less emotionally attached to our beliefs. In other words, I think there's a lot to say for humility. When you see something online that is upsetting or angering or frustrating, instead of jumping to conclusions about that person or that cause, maybe sit back and say, I don't know. What the fuck am I saying? You guys aren't going to do that. Let's be honest. Last year, I created an online course that helped people challenge their own beliefs. It helped people figure out how to hold opinions a little bit more softly. Funny, funny thing. Nobody fucking took the course. For some reason, there wasn't a ton of demand for that. And not to mention, it's fucking hard to market. How do you market a thing to people that's going to make them feel wrong about everything they believe in their life? That's not exactly the most enticing sales pitch. But if for some reason you want to take that course, you can find the link in the description. Good fucking luck. So when it comes to other people, I think one of the hard truths that I've had to swallow over the years is that you can't really change the mind of somebody who's not willing to have their mind changed. You can throw as much data and statistics and logical arguments at them, but they're just going to ninjitsu that shit, pull a Neo in the Matrix, and all the bullets are going to get by them. I think this is because most people's beliefs are not based on logic or reason. Most people's beliefs are based on identity and group affiliation. And so when you show them contradicting data, their thought process isn't, oh, I need to update my prior assumptions about the world. Their thought process is like, I'm being attacked. My tribe is being attacked. You know, many years ago, I used to coach people. And one of the reasons I fucking stopped coaching people is because it was often very frustrating. Somebody would hire me for a week or we'd do like a monthly call or something. And it just felt like I was like beating my head against a wall. Like I was telling them the same thing over and over and over again. Usually like deep, profound truths don't sink in for people the first time. It's almost like you plant the seed in their head and then they need to go live for another year or two for that idea to sprout. It's almost like we have to be in the right environment or context or be going through the right phase of our journey for those seeds to sprout. So one thing that has helped me a lot in my own relationships and just fucking tolerating all the nonsense that goes on in the world is understanding that I'm not here to change minds necessarily. I'm here to plant seeds. I'm here to drop an idea or an argument so that one day if that person becomes fertile ground, that seed can sprout. The most impactful things usually don't sink in right away. They usually need like a few weeks or months or even a couple of years to like incubate in a person's head. And when I look at my own life, this also feels true. Like there were things that people told me in my teens that I didn't fully appreciate until my 20s or 30s or hell, even almost 40. Ultimately, I think humility is one of the most underrated values in our world right now. On the internet, people are rewarded for false confidence. People are rewarded for being bold. People are rewarded for being zealots and fanatics about things. But while the algorithms may reward bluster and bullshit, the real world doesn't. Life is really fucking difficult and complicated and most of us don't really know what we're doing most of the time. So any sense of false certainty is really just going to cause more pain than necessary. I think what the Dunning-Kruger effect really teaches us is that humility is actually very practical. By intentionally underestimating our own understanding of things, not only do we open ourselves up to learn and grow more, but we also prevent ourselves from just being a fucking narcissistic ass face on the internet. That is, of course, until we decide that I'm the most humble person you ever met. Man, I'm so fucking humble, you wouldn't believe it. Everybody thinks they're humble, but I'm really humble. Like, I've got this humility shit down. They should bottle it up and put that shit on eBay because I'm going to make a fucking killing. Humility, like, off the charts. You can't even see how high it is up there, man. Camera doesn't go that high. It's that humble. That fucking humble. And as you can see, now we're back to square one. We're back to square one."}